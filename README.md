# Scraping C2C Experiments

## Description
Repo containing different approaches to scraping bus seat data from C2C, Cornell's official bus service.

## Installation
1. Clone the repo
2. Run `npm i` to install the necessary packages
3. Run `npm run dev` to compile the typescript files in `/src/` to javascript
4. Run `node dist/*FILE*.js` for your intended program (e.g. index, puppeteer, selenium)

## Commentary/Blog Post

The C2C website is an ASP.NET web application, which makes getting data from the website a bit difficult, as the website sends POST network requests to load data with some parameters to track state across requests (e.g. "__EVENTVALIDATION"). Therefore, it is not possible to just send a simple GET request to get the necessary data from the website. 

There are two main approaches to scraping data from this website:
1. Sending multiple fetch network requests to simulate the process of running the C2C website (index.ts)
2. Using headless browser to simulate and automate the steps of a user (puppeteer.ts, selenium.ts)

### index.ts - ❌
This was my original approach. After opening up Chrome DevTools and looking at the Network tab, I discovered that the C2C website sends POST requests to the site with form data (application/x-www-form-urlencoded) *every* time the user updates a field on the form. After further research, I concluded that in order to get the seat data at the end, every step that the user made (and, thus, the network requests generated by the user's actions) would need to be simulated by a script that wanted to scrape that data. The cookies sent by the website would also needed to be saved to be used in subsequent requests. Thus, I came up with the following steps:
1. Go to main page (https://c2cbus.ipp.cornell.edu/mobile/?a=mobile)
    1. Get the necessary fields for the next request's form data and save them (i.e. __EVENTVALIDATION, vs_gid)
    2. Get the cookies (from getSetCookie()) and save them
2. Set ddlTripType to 'One Way' and ddlQty to '1' and send the necessary POST request
    1. Send the necessary POST request with these two changes and the other form data (i.e. __EVENTVALIDATION, vs_gid, etc.)
    2. After getting the response from the POST request, save the updated __EVENTVALIDATION for the next step (note that vs_gid doesn't update from step 1)
3. Select ddlDepPickLocation and send the necessary POST request
    1. Send the necessary POST request with this change and the other form data (i.e. __EVENTVALIDATION, vs_gid, etc.)
    2. After getting the response from the POST request, save the updated __EVENTVALIDATION for the next step
4. Select ddlDepDropLocation and send the necessary POST request
    1. Send the necessary POST request with this change and the other form data (i.e. __EVENTVALIDATION, vs_gid, etc.)
    2. After getting the response from the POST request, save the updated __EVENTVALIDATION for the next step
5. Select btnDepCal and send the necessary POST request
    1. Send the necessary POST request with this change and the other form data (i.e. __EVENTVALIDATION, vs_gid, etc.)
    2. After getting the response from the POST request, save the updated __EVENTVALIDATION for the next step
6. Parse the results
In theory, this approach should work, but for whatever reason, this script is treated differently than a user (maybe because of cookies?). Thus, this led me to try another approach.

### selenium.ts - ✅
I decided to use Selenium because I knew that it would 100% work as it simulated the actions of a user on a web page. To make Selenium (and eventually Puppeteer as well) work, I needed to find the elements and carry actions out on it. Most of the time, this was pretty easy, as most elements had unique id properties. However, some elements, like the date picker's button to increase the date had some weird HTML, which forced me to use its XPATH to find and interact with the element. In addition, as the C2C website is a dynamic website, it is important to tell Selenium to wait for elements to appear with the setTimeouts() method. In the end, Selenium worked perfectly, as expected. It was not as slow as I expected, with an average runtime of ~2 seconds on my machine (M1 MacBook Air, 16GB).

### puppeteer.ts - ✅
Although the Selenium approach worked, I decided to translate my Selenium code to Puppeteer, another library that allows you to control a headless browser (i.e. Chrome) through Javascript. The reason for this move was because there didn't appear to be much support for Selenium on Vercel's serverless functions platform. However, people managed to run Puppeteer on Vercel, albeit, their solutions were a bit finicky. 

I found Puppeteer to be a bit harder to use than Selenium. For example, in Puppeteer, you need to explicitly call the waitForSelector() method before you want to interact with an element that hasn't yet appeared (as opposed to Selenium's one-time invocation of setTimeouts() method). In addition, a frustrating bug was that [you have to explicitly tell Puppeteer to wait for an element to be visible before you interact with it](https://stackoverflow.com/a/55212494). Otherwise, you would just be looking if that element exists in the DOM. After finally solving those issues, I got Puppeteer to work, and it was indeed faster than Selenium with an average runtime of ~1-1.5 seconds on my machine (M1 MacBook Air, 16GB).

Now that this puppeteer script works, I hope to deploy it on Vercel for my project, [CUSoon](https://cusoon.vercel.app).